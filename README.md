# Programming for humanities scholars II: NLP with Python

## Objective:
This workshop aims to provide humanities scholars with advanced techniques to efficiently handle, model, transform, and visually present text and tabular data. The focus will be on user-friendly yet powerful tools and libraries to make modern data analysis and visualization methods accessible.

### Prerequisites:
Participants should have basic knowledge of Python, including loops, conditions, functions, lists, dictionaries, and experience in creating a simple word counter.

### Workshop Format:
- **Duration:** 8 hours (including breaks)
- **Format:** Theoretical introductions interspersed with practical exercise sessions.
- **Tools:** Jupyter Notebooks, Python (Pandas, Matplotlib, Seaborn), with optional use of Tableau for additional visualizations, and an introduction to NLP tools like SpaCy and API requests to GPT.

## Schedule and Content

### Part 0: Introduction to Jupyter Notebooks (1 hour)
- **Goals:** Familiarize participants with the Jupyter Notebook environment, which will be used throughout the workshop.
- **Content:**
  - Overview of Jupyter Notebooks: installation, launching, and basic navigation.
  - Understanding and creating cells (Markdown vs Code).
  - Running code and documenting work within notebooks.
  - Practical exercise: Creating a simple notebook with basic Python code and Markdown documentation.

### Part 1: Introduction to Data Modeling (1 hour)
- **Goals:** Understanding data structures and data modeling concepts.
- **Content:**
  - Brief review of Python data structures.
  - Introduction to advanced data structures (Sets, Tuples) and their use cases.
  - Fundamental data modeling concepts: entities, relationships.
  - Hands-on exercise: Model a small dataset relevant to the humanities.

### Part 2: Data Handling and Transformation with Pandas (1 hours)
- **Goals:** Learn techniques for data preparation and transformation.
- **Content:**
  - Introduction to Pandas: DataFrames and Series.
  - Loading, inspecting, and cleaning data (e.g., text files, CSV).
  - Data transformation: filtering, sorting, grouping.
  - Practical exercise: Apply concepts to a real dataset (e.g., literary texts, historical records).

### Part 3: Introduction to Data Visualization (1 hour)
- **Goals:** Understand and apply basic data visualization techniques.
- **Content:**
  - Visualization concepts: choosing the right type of visualization.
  - Introduction to Matplotlib and Seaborn for creating basic plots.
  - Hands-on exercise: Create various charts (bar charts, line graphs, scatter plots) based on the previously transformed dataset.

### Part 4: Interactive Data Visualization and Final Project (1 hour)
- **Goals:** Apply interactive visualization to illustrate complex data relationships.
- **Content:**
  - Brief introduction to interactive visualization tools (e.g., Tableau, Plotly).
  - Participants choose a dataset and apply what they have learned: data modeling, transformation, and visualization.
  - Presentation and discussion of results.

### Part 5: Introduction to Natural Language Processing (NLP) with SpaCy (2 hours)
- **Goals:** Basic understanding of NLP and practical use of the SpaCy library.
- **Content:**
  - Overview of NLP and its applications in the humanities.
  - Introduction to SpaCy: installation, basic usage, and common NLP tasks (tokenization, part-of-speech tagging, named entity recognition).
  - Practical exercise: Extract named entities from a sample text and perform basic text analysis.

### Part 6: Making API Requests to a GPT API (1 hour)
- **Goals:** Learn the basics of making API requests and interacting with GPT APIs for advanced text processing.
- **Content:**
  - Overview of APIs and their importance in data processing.
  - Introduction to making API requests using Python's `requests` library.
  - Demonstration: Making a request to a GPT API for text generation, summarization, or translation.
  - Practical exercise: Participants make their own API requests and process the responses for a specific task.

---

## Materials and Resources

- **Jupyter Notebooks** for all practical exercises.
- **Datasets** from the humanities, prepared for use in the workshop.
- **Access to online resources** for further information and learning materials.

### Notes for Participants:
- It is recommended to bring a personal laptop with pre-installed Python and the mentioned libraries (Pandas, Matplotlib, Seaborn, SpaCy). Installation guides for these tools will be provided prior to the workshop.
- No prior experience with Pandas, visualization tools, or NLP libraries is needed.

Through this workshop, participants will be able to independently conduct data projects from conception to visual presentation and effectively analyze and interpret complex datasets using advanced Python tools.
